# ===================================================================
# Main Configuration File for AI Image Restoration Project
# ===================================================================

# -------------------------------------------------------------------
# 1. Data Preparation Configuration (`scripts/prepare_dataset.py`)
# -------------------------------------------------------------------
data:
  # Source directory containing the raw, high-resolution images.
  hr_dir: ./data/hr
  # Main directory where the processed training dataset will be created.
  dataset_dir: ./data/dataset
  # Sharpness threshold. Images below this value are considered blurry
  # and moved to the 'blur' folder instead of being processed.
  sharpness_threshold: 150

# -------------------------------------------------------------------
# 2. Validation Set Creation (`scripts/create_validation_set.py`)
# -------------------------------------------------------------------
validation_set:
  # Source directory for HR training images. Should match data.dataset_dir + /train/1_
  train_dir: ./data/dataset/train/1_
  # Source directory for LR training images. Should match data.dataset_dir + /reg/1_
  reg_dir: ./data/dataset/reg/1_
  # Destination for HR validation images.
  hr_dir: ./data/val/hr
  # Destination for LR validation images.
  lr_dir: ./data/val/lr
  # Number of images to move from the training set to create the validation set.
  num_val_files: 1000

# -------------------------------------------------------------------
# 3. Inference Configuration (`scripts/run_inference.py`)
# -------------------------------------------------------------------
inference:
  # Path to the base Stable Diffusion model.
  base_model_path: ./models/base/realisticVisionV60B1_v51HyperVAE.safetensors
  # Path to your trained LoRA model.
  lora_path: ./models/lora/Realistic_Vision-step00005000.safetensors
  # Directory containing the images you want to repair.
  input_dir: ./data/val/lr
  # Directory where the repaired images will be saved.
  output_dir: ./outputs/inference_results
  # Inference parameters
  prompt: "highly detailed, realistic skin texture, natural skin tone, sharp features, 8K UHD"
  strength: 0.25
  cfg_scale: 7.0
  steps: 28
  seed: 42

# -------------------------------------------------------------------
# 4. Evaluation Configuration (`scripts/run_evaluation.py`)
# -------------------------------------------------------------------
evaluation:
  # Directory with the original, high-resolution ground truth images.
  ground_truth_dir: ./data/val/hr
  # Directory with the images generated by the model.
  generated_dir: ./outputs/inference_results
  # Directory to save evaluation charts and summary reports.
  output_dir: ./outputs/evaluation_results

# -------------------------------------------------------------------
# 5. Full Validation Pipeline (`scripts/run_validation.py`)
# -------------------------------------------------------------------
# This pipeline runs both inference and evaluation sequentially.
# It uses the paths and parameters from the 'inference' and 'evaluation' sections above,
# but you can specify dedicated paths for the full validation run here.
validation_pipeline:
  base_model_path: ./models/base/realisticVisionV60B1_v51HyperVAE.safetensors
  lora_path: ./models/lora/Realistic_Vision-step00005000.safetensors
  hr_folder: ./data/val/hr
  lr_folder: ./data/val/lr
  generate_folder: ./outputs/val/generated
  output_dir: ./outputs/val/evaluation
  # Inference parameters for the validation run
  prompt: "highly detailed, realistic skin texture, natural skin tone, sharp features, 8K UHD"
  strength: 0.25
  cfg_scale: 7.0
  steps: 28
  seed: 42

